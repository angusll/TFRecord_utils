{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0388cb182541d7891a0e82db732276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tnrange, tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from atpbar import atpbar\n",
    "from mantichora import mantichora\n",
    "import json\n",
    "\n",
    "from TFRecord_config import configs\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class To_TFRecord_Config:\n",
    "    train_or_valid: str\n",
    "    tile_size : str\n",
    "    csv_fp : str\n",
    "    class_indice_fp : str\n",
    "c = To_TFRecord_Config(**configs)\n",
    "\n",
    "output_dir = f'/home/agsl0905/PDL1_HER2_data/tpu_data/retrain_from_scratch/tile_{c.tile_size}/{c.train_or_valid}'\n",
    "\n",
    "df_data = pd.read_csv(c.csv_fp,index_col=0)\n",
    "df_data.reset_index(inplace=True,drop=True)\n",
    "df_data = df_data.sample(frac=1,random_state = 123).reset_index(drop=True) # shuffle df\n",
    "# Load class indice\n",
    "f = open(c.class_indice_fp)\n",
    "class_indice = json.load(f)\n",
    "one_hot_map = {v:k for k,v in class_indice.items()} # reverse class_indice for one hot encoding\n",
    "\n",
    "# slicing df into partitions base on cpu count\n",
    "#permuted_indices = np.random.permutation(len(df_data))\n",
    "dfs = np.array_split(df_data, np.ceil(len(df_data)/5000))# each partition has ~2500 images, ~1000MB per tfrecord\n",
    "dfs = [df.reset_index(drop=True) for df in dfs]\n",
    "N_PARTITIONS = len(dfs) # each partition has ~2500 images, ~1000MB per tfrecord\n",
    "print(\"Number of partitions:\", N_PARTITIONS)\n",
    "\n",
    "def _bytestring_feature(list_of_bytestrings):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n",
    "\n",
    "def _int_feature(list_of_ints): # int64\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n",
    "\n",
    "def _float_feature(list_of_floats): # float32\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n",
    "\n",
    "def csv_to_TFRecord(df,partition):\n",
    "    os.makedirs(output_dir,exist_ok=True)\n",
    "    output_fp = os.path.join(output_dir,f'PDL1_{c.train_or_valid}_data_examples_{df.shape[0]}_{partition}_.tfrec')\n",
    "    corrupted = []\n",
    "    writer = tf.io.TFRecordWriter(output_fp)\n",
    "\n",
    "    for j in atpbar(range(len(df)), name=f'partition {partition} of {N_PARTITIONS}'):\n",
    "        fp = df.loc[j,'fp']\n",
    "        bits = tf.io.read_file(fp)\n",
    "        \n",
    "        try:\n",
    "            image = tf.image.decode_png(bits,channels=3)\n",
    "            image = tf.cast(tf.image.resize(image,[296,296]),tf.uint8)\n",
    "            height = image.shape[0]\n",
    "            width = image.shape[1]\n",
    "            encoded_image = tf.image.encode_png(image)     \n",
    "            label = str.encode(df.loc[j,'label'])\n",
    "            class_num = int(one_hot_map.get(label.decode(\"utf-8\")))\n",
    "            one_hot_class = np.eye(len(class_indice))[class_num].astype(np.int8)\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={'image' :  _bytestring_feature([encoded_image.numpy()]), # .numpy() is needed to turn a tensor to byte\n",
    "                                                                            \"class\":        _int_feature([class_num]),              # one class in the list\n",
    "                                                                            \"label\":         _bytestring_feature([label]),          # fixed length (1) list of strings, the text label\n",
    "                                                                            \"size\":          _int_feature([height, width]),         # fixed length (2) list of ints\n",
    "                                                                            \"one_hot_class\": _float_feature(one_hot_class.tolist())})) # variable length  list of floats, n=len(CLASSES)\n",
    "\n",
    "\n",
    "\n",
    "            writer.write(example.SerializeToString())\n",
    "        except:\n",
    "            print(f'{fp} is corrupted')\n",
    "            corrupted.append(fp)\n",
    "    writer.close()\n",
    "    return corrupted\n",
    "\n",
    "with mantichora(nworkers=32) as mcore:\n",
    "    for i in range(len(dfs)):\n",
    "        mcore.run(csv_to_TFRecord,dfs[i],i)\n",
    "    results = mcore.returns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
